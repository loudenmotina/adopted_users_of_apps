# -*- coding: utf-8 -*-
"""project_takehome.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FUwjh5rb9YMsKo6bprvIR1pNO2d0da4-

Project Title:understanding what variables can influence app users converting into an adopted user.

we start by importing the user engagement dataset to enable us understand the engagement of 12,000 users who signed up for the product in the last two years.
"""

#import packages
import pandas as pd
from datetime import datetime

df=pd.read_csv('takehome_user_engagement.csv')
df4=df.copy()
df8=df.copy()
df.head(10)
df['time_stamp']=pd.to_datetime(df['time_stamp'])
df.info()

df['user_id'].nunique()

"""we have 8823 users of the app in the past two years"""

df1=df.rename(columns={'time_stamp':'time_s'})
#df1.time_s=pd.to_datetime(df1['time_s'], format ='%d%b%Y:%H:%M:%S.%f')
df.info()

import numpy as np
dff=df.user_id.value_counts()
dff2=dff.reset_index()
dff2.columns=['user_id','counts']
x1=dff2.counts[dff2.counts<3].count()
x2=dff2.counts[dff2.counts>=3].count()
x2

"""from the count it shows out of the 8823 users, 6575 visited the app < 3 times. thus 2248 users visited 3 times and above"""

df.user_id.value_counts().sort_values(ascending=False).head(80).plot(kind='barh',figsize=(10, 10), title='top users of the app for two years')

import matplotlib.pyplot as plt
x=['users visited app less than 3 times','visited app 3 or more times']
y=[x1,x2]
total= x1+x2
percentages = [(y / total) * 100 for count in y]
plt.bar(x,y,color=['Red','Blue'], linestyle='--', alpha=0.7)
percentages

"""we will focus on the users who visited 3 or more times to know those who did for 3 different days in a week"""

user_visited_counts = df['user_id'].value_counts()
df['user_visited_counts'] = df['user_id'].map(user_visited_counts)
df=df[df['user_visited_counts']>=3].sort_values(by='user_visited_counts' ,ascending=False)

df.head(30)

# Sort and group by 'user_id'
dfg=df.loc[:, 'time_stamp':'user_id']
dfg.sort_values(by=['user_id', 'time_stamp'], inplace=True)
group_users = dfg.groupby('user_id')

# lets get a list of adopted users
adopted_users = []
for user, group in group_users:
    rolling_window = group['time_stamp'].rolling(window=7)
    login_counts = rolling_window.count()
    if any(login_counts >= 3):
        adopted_users.append(user)
print("Adopted Users:", adopted_users)

"""out of the 8823 users, 2248 are adopted users"""

len(adopted_users)

adoptedu=pd.DataFrame(adopted_users)
adoptedu.columns=['adopted_usersid']
adoptedu

dfhome=pd.read_csv('takehome_users.csv',encoding='latin1')
dfhome.info()

"""we will perform an inner join on the adapted users dataframe to be able to show know the adopted users and look at the characteristics if there are trends that can be proposed to new users"""

new_df=dfhome.merge(adoptedu,how='inner',left_on='object_id',right_on='adopted_usersid')
new_df

"""performing EDA to see features that may influence the adopted_users"""

new_df.info()

new_df['creation_time']=pd.to_datetime(new_df['creation_time'])
new_df['last_session_creation_time'] = pd.to_datetime(new_df['last_session_creation_time'], unit='s')
new_df

new_df['year'] = new_df['creation_time'].dt.year
#new_df['year'].value_counts().plot(kind='barh')
#new_df['creation_time'].sort_values()
new_df['month'] = new_df['creation_time'].dt.month
new_df['month'].value_counts().plot(kind='barh')

import matplotlib.pyplot as plt
new_df['period_usage']=new_df['last_session_creation_time']-new_df['creation_time']
x10=len(new_df[new_df['period_usage']>='1 days'])
x11=len(new_df[new_df['period_usage']>='30 days'])
x12=len(new_df[new_df['period_usage']>='90 days'])
x13=len(new_df[new_df['period_usage']>='180 days'])
x14=len(new_df[new_df['period_usage']>='365 days'])
x15=len(new_df[new_df['period_usage']>='547 days'])
x16=len(new_df[new_df['period_usage']>='700 days'])
y=[x10,x11,x12,x13,x14,x15,x16]
xf=['current users','users >1 months','users>3 months','users > 6 months','users since 1 year','users since 1year 6months','users since 2 years ago']
plt.barh(xf,y)

x21=new_df.invited_by_user_id.isna().sum()
x22=new_df.invited_by_user_id.notnull().sum()
y=[x22,x21]
x2=['invited by users','not invited by users']
plt.bar(x2,y)

new_df3=new_df.groupby('org_id')['name'].size().sort_values(ascending=True)
new_df5=new_df.groupby('invited_by_user_id')['name'].size().sort_values(ascending=False)
new_df5=new_df5[new_df5>=3].count()
new_df5

new_df1=new_df.groupby('creation_source')['name'].size().sort_values(ascending=True).plot(kind='pie',figsize=(10, 5), title='users by creation_source')

new_df.describe()
print('opted into mailing',new_df['opted_in_to_mailing_list'].value_counts())
new_df['enabled_for_marketing_drip'].value_counts()

c1=new_df['org_id'].value_counts().sort_values(ascending=False).head(30).plot(kind='barh')

#adoptedu

non_adoptedu=dfhome.merge(adoptedu,how='outer',left_on='object_id',right_on='adopted_usersid')

non_adopt= non_adoptedu[non_adoptedu['adopted_usersid'].isnull()]
non_adopt['last_session_creation_time'] = pd.to_datetime(non_adopt['last_session_creation_time'], unit='s')
non_adopt['creation_time']=pd.to_datetime(non_adopt['creation_time'])
non_adopt

x31=non_adopt.invited_by_user_id.isna().sum()
x32=non_adopt.invited_by_user_id.notnull().sum()
yq=[x32,x31]
xq=['invited by users','not invited by users']
plt.bar(xq,yq,color=['blue','Green'])

print('opted into mailing',non_adopt['opted_in_to_mailing_list'].value_counts())
non_adopt['enabled_for_marketing_drip'].value_counts()

non_adopt['year'] = non_adopt['creation_time'].dt.year
non_adopt['year'].value_counts().plot(kind='barh')

"""from the figure above and relative to the number of users that are adopted it shows that in 2014 had the high % of users who are not adopted and 2012 had more adopted users relative to the total users that year
so top management has to look at some strategies that were implimented in 2012 or the market compitition
"""

non_adopt['month'] = non_adopt['creation_time'].dt.month
non_adopt['month'].value_counts().plot(kind='barh')

"""from the figure it shows that clients in month may are not adopted while month 8,3, and 8 are good months were more adopted members and less non adopted members relative to the other months"""

c2=non_adopt['org_id'].value_counts().head(20).plot(kind='barh')

new_d=non_adopt.groupby('creation_source')['name'].size().sort_values(ascending=True).plot(kind='pie',figsize=(10, 5), title='users by creation_source')

"""from this bar chat we see that less users  who signed up using google and guest invite out of total were not adopted users compared to more users who were org invite and personal projects let the app
therefor management should invest more on google signups and guest invite

Feature engineering for modeling
"""

data=non_adoptedu.apply(lambda x: 0 if pd.isnull(x['adopted_usersid']) else 1,axis=1)
non_adoptedu['Adopted_User']=data
non_adoptedu2=non_adoptedu.drop(['adopted_usersid','email','name'], axis=1)
non_adoptedu2['org_id'].value_counts()
non_adoptedu2['last_session_creation_time'] = pd.to_datetime(non_adoptedu2['last_session_creation_time'], unit='s')
non_adoptedu2['creation_time']=pd.to_datetime(non_adoptedu2['creation_time'])
non_adoptedu2['year'] = non_adoptedu2['creation_time'].dt.year
non_adoptedu2['month'] = non_adoptedu2['creation_time'].dt.month
non_adoptedu2['period_usage']=non_adoptedu2['last_session_creation_time']-non_adoptedu2['creation_time']
non_adoptedu2
non_adoptedu2['creation_source'].isnull().sum()
non_adoptedu2.head(50)

non_adoptedu22=non_adoptedu2.apply(lambda x: str(x['period_usage']).split(' ')[0],axis=1)
non_adoptedu2['period_usage']=non_adoptedu22
non_adoptedu2=non_adoptedu2.drop(['last_session_creation_time'], axis=1)
non_adoptedu2['invited_by_user_id'].fillna(0, inplace=True)
non_adoptedu2.head(30)

non_adoptedu2.creation_source.value_counts()

one_hot_encoded = pd.get_dummies(non_adoptedu2.creation_source)
one_hot_encoded
dfencoded = pd.concat([non_adoptedu2, one_hot_encoded], axis=1)
dfencoded=dfencoded.drop(['object_id','creation_time','creation_source'],axis=1)
value_counts=dfencoded.invited_by_user_id.value_counts()
value_counts

#grouping the invited by user_id in to categories based on their counts
category=dfencoded.invited_by_user_id


count_intervals = [(1, 4), (5, 9), (10, 13)]
integer_codes = [1, 2, 3]

# Create a mapping of categories to integer codes based on intervals
category_to_code = {}

for interval, code in zip(count_intervals, integer_codes):
    lower_bound, upper_bound = interval
    for category, count in value_counts.items():
        if lower_bound <= count <= upper_bound:
            category_to_code[category] = code
# Apply integer encoding based on the defined intervals
dfencoded['category_of_invited_user'] = dfencoded.invited_by_user_id.map(category_to_code)
dfencoded['category_of_invited_user'].fillna(0,inplace=True)
dfencoded['period_usage']=dfencoded['period_usage'].replace({'NaT':0})
v_counts=dfencoded.org_id.value_counts()
dfencoded

#grouping the org_id in to categories based on their counts
#lower_bound = 1
#upper_bound = 13
categories=dfencoded.org_id


count_intervals2 = [(1, 100), (101, 200), (201, 300),(301,400)]
integer_codes1 = [0,1, 2, 3]

# Create a mapping of categories to integer codes based on intervals
category_to_code1 = {}

for interval1, code1 in zip(count_intervals2, integer_codes1):
    lower_bound, upper_bound = interval1
    for categories, count in v_counts.items():
        if lower_bound <= count <= upper_bound:
            category_to_code1[categories] = code1
# Apply integer encoding based on the defined intervals
dfencoded['category_of_group_org'] = dfencoded.org_id.map(category_to_code1)
dfencoded

"""Modeling
based on the problem we have to build a model which can predict if a new user will become an adopted user or not based on all the factors that we have gathered that influences this decision.
this model will help the business to improve aspects of its business.
"""

X=dfencoded.drop(['Adopted_User','invited_by_user_id','org_id'],axis=1)
Y=dfencoded['Adopted_User']
X

"""basicly this is a binary classification problem so we will test several binary classification models like logistic regression,DT,RF,SVM etc and see which one is best"""

#import usefull packages for modelling
#!pip install keras
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
#from keras.wrappers.scikit_learn import KerasClassifier
from xgboost import XGBClassifier

from sklearn.metrics import mean_absolute_error, accuracy_score, classification_report, confusion_matrix
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestClassifier
#!pip install mlflow
import mlflow.sklearn
import numpy as np

# We will split data and apply oneHot encoder on all categories we generated to avoid dimensionality issues of the different classes
X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2)
ohe=OneHotEncoder()
ohe.fit(X[['category_of_invited_user','category_of_group_org','year','month']])
column_trans=make_column_transformer((OneHotEncoder(categories=ohe.categories_),['category_of_invited_user','category_of_group_org','year','month']),remainder='passthrough')

with mlflow.start_run():
  lr=LogisticRegression()
  log_reg=make_pipeline(column_trans,lr)
  log_reg.fit(X_train,y_train)
  y_train_pred1 = log_reg.predict(X_train)
  y_pred=log_reg.predict(X_test)
  accuracyt= metrics.accuracy_score(y_train, y_train_pred1)
  accuracy= metrics.accuracy_score(y_test, y_pred)
  print(classification_report(y_test, y_pred))
  print('lr train accuracy is:',accuracyt)
  print('lr test accuracy is:',accuracy)
  #mlflow.log_params({'param1': value1, 'param2': value2})
  mlflow.log_metric('accuracy', accuracy)
  mlflow.sklearn.log_model(log_reg,"model")
  #mlflow.sklearn.save_model(log_reg,"logisticReg1")
  #mlflow.log_artifact("logisticR.png")

with mlflow.start_run():
  rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=42)
  rf=make_pipeline(column_trans,rf_classifier )
  rf.fit(X_train,y_train)
  y_train_pred = rf.predict(X_train)
  y_pred=rf.predict(X_test)
  accuracytrain= metrics.accuracy_score(y_train, y_train_pred)
  accuracy2= metrics.accuracy_score(y_test, y_pred)
  print('rf train accuracy is:',accuracytrain)
  print('rf test accuracy is:',accuracy2)
  #mlflow.log_params({'param1': value1, 'param2': value2})
  mlflow.log_metric('accuracy', accuracy2)
  mlflow.sklearn.log_model(rf,"model")

"""but the data is imbalance so we will try methods that can handle imbalance data like RF which didnot do much
we will use over sampling technichs since in this case the non adopted users are 4.3 times the adopted users in the data set
"""

dfad1=dfencoded[dfencoded['Adopted_User']==1]
duplicated_df = pd.concat([dfad1] * 3, ignore_index=True)

oversampled_data=pd.concat([dfencoded,duplicated_df],ignore_index=True)
oversampled_data.Adopted_User.value_counts()
oversampled_data

"""from the value count the two categories now have similar sample size and we expect the model not to under fit"""

X1=oversampled_data.drop(['Adopted_User','invited_by_user_id','org_id'],axis=1)
Y1=oversampled_data['Adopted_User']
X_train1,X_test1,y_train1,y_test1=train_test_split(X1,Y1,test_size=0.2)
ohe2=OneHotEncoder()
ohe2.fit(X1[['category_of_invited_user','category_of_group_org','year','month']])
column_trans2=make_column_transformer((OneHotEncoder(categories=ohe2.categories_),['category_of_invited_user','category_of_group_org','year','month']),remainder='passthrough')

with mlflow.start_run():
  lr2=LogisticRegression(random_state=100)
  log_reg1=make_pipeline(column_trans2,lr2)
  log_reg1.fit(X_train1,y_train1)
  y_train_pred2 = log_reg1.predict(X_train1)
  y_pred1=log_reg1.predict(X_test1)
  accuracyt1= metrics.accuracy_score(y_train1, y_train_pred2)
  accuracyt2= metrics.accuracy_score(y_test1, y_pred1)
  print(classification_report(y_test1, y_pred1))
  print('lr train accuracy is:',accuracyt1)
  print('lr test accuracy is:',accuracyt2)
  #mlflow.log_params({'param1': value1, 'param2': value2})
  mlflow.log_metric('accuracy', accuracyt2)
  mlflow.sklearn.log_model(log_reg1,"best_model")
  #mlflow.sklearn.save_model(log_reg1,"best_model")
  #mlflow.log_artifact("logisticR.png")
  y_pred3=log_reg1.predict(X_test1.head(5))
  print(y_pred3)

loaded_model = mlflow.sklearn.load_model("best_model")
pred1=loaded_model.predict(X_test1.head(5))
pred1
#X_test.head(3)

!mlflow ui --port 5000 &